# scripts/train_and_verify.py
"""
è®­ç»ƒå¹¶éªŒè¯è„šæœ¬
ç”¨äºè®­ç»ƒå°‘é‡epochåï¼Œç«‹å³æ£€æµ‹HSIæ¨¡æ€æ˜¯å¦è¢«æœ‰æ•ˆå¿½ç•¥
"""

import torch
import torch.nn as nn
import argparse
import os
import sys
from PIL import Image
import numpy as np
import warnings
import gc # å¯¼å…¥gcæ¨¡å—

# å¯¼å…¥æ‚¨é¡¹ç›®ä¸­çš„ç°æœ‰æ¨¡å—
from train_qwen_fixed import MemoryEfficientQwenTrainer  # å¤ç”¨æ‚¨å·²ç»å®Œå–„çš„è®­ç»ƒå™¨
from models.main_model_qwen import MultiModalPestDetectionWithQwen
from transformers import AutoTokenizer
import albumentations as A
from albumentations.pytorch import ToTensorV2

warnings.filterwarnings('ignore')

def run_verification_test(checkpoint_path: str, qwen_path: str, verify_rgb_image: str, num_classes: int, device: str):
    """
    æ‰§è¡Œæ•æ„Ÿæ€§æµ‹è¯•ä»¥éªŒè¯HSIæ˜¯å¦è¢«å¿½ç•¥
    """
    print("\n" + "="*60)
    print(" ğŸš€ å¼€å§‹æ‰§è¡ŒHSIæ¨¡æ€æ•æ„Ÿæ€§éªŒè¯ ")
    print("="*60)

    # 1. åŠ è½½åˆšåˆšè®­ç»ƒå¥½çš„æ¨¡å‹
    print(f"[éªŒè¯æ­¥éª¤ 1] æ­£åœ¨åŠ è½½æ¨¡å‹: {checkpoint_path}")
    model = MultiModalPestDetectionWithQwen(
        num_classes=num_classes,
        qwen_path=qwen_path,
        use_hsi=False,  # å¿…é¡»ä»¥æ— HSIæ¨¡å¼åŠ è½½
        use_lora=True
    )
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    
    state_dict = checkpoint['model_state_dict']
    new_state_dict = {}
    for k, v in state_dict.items():
        new_key = k.replace('module.', '')
        new_state_dict[new_key] = v
        
    model.load_state_dict(new_state_dict, strict=False)
    model = model.to(device)
    model.eval()
    print("æ¨¡å‹åŠ è½½æˆåŠŸï¼")

    # 2. å‡†å¤‡è¾“å…¥æ•°æ®
    print("\n[éªŒè¯æ­¥éª¤ 2] æ­£åœ¨å‡†å¤‡è¾“å…¥æ•°æ®...")
    rgb_transform = A.Compose([
        A.Resize(224, 224),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2()
    ])
    rgb_image = Image.open(verify_rgb_image).convert('RGB')
    rgb_tensor = rgb_transform(image=np.array(rgb_image))['image'].unsqueeze(0).to(device)

    tokenizer = AutoTokenizer.from_pretrained('bert-base-chinese')
    text = "ä¸€ç‰‡æœ‰ç—…æ–‘çš„æ¤ç‰©å¶å­"
    text_encoded = tokenizer(text, padding='max_length', truncation=True, max_length=128, return_tensors='pt')
    text_ids = text_encoded['input_ids'].to(device)
    text_mask = text_encoded['attention_mask'].to(device)

    hsi_zeros = torch.zeros(1, 224, 64, 64).to(device)
    hsi_random = torch.randn(1, 224, 64, 64).to(device)
    print("è¾“å…¥æ•°æ®å‡†å¤‡å®Œæ¯•ã€‚")

    # 3. æ‰§è¡Œä¸¤æ¬¡æ¨ç†å¹¶æ¯”è¾ƒç»“æœ
    print("\n[éªŒè¯æ­¥éª¤ 3] æ­£åœ¨æ‰§è¡Œä¸¤æ¬¡æ¨ç†å¹¶æ¯”è¾ƒ...")
    with torch.no_grad():
        logits_with_zeros = model(rgb_tensor, hsi_zeros, text_ids, text_mask)['logits']
        print("å®Œæˆç¬¬ä¸€æ¬¡æ¨ç† (ä½¿ç”¨å…¨é›¶HSI)ã€‚")
        
        logits_with_random = model(rgb_tensor, hsi_random, text_ids, text_mask)['logits']
        print("å®Œæˆç¬¬äºŒæ¬¡æ¨ç† (ä½¿ç”¨éšæœºHSI)ã€‚")

    abs_diff = torch.abs(logits_with_zeros - logits_with_random).mean().item()
    is_close = torch.allclose(logits_with_zeros, logits_with_random, atol=1e-5)

    print(f"\nä¸¤æ¬¡æ¨ç†è¾“å‡ºçš„å¹³å‡ç»å¯¹å·®å¼‚: {abs_diff:.8f}")
    
    print("\n" + "="*60)
    print(" æœ€ç»ˆéªŒè¯ç»“è®º ")
    print("="*60)
    if is_close:
        print("âœ… éªŒè¯é€šè¿‡ï¼šHSIæ¨¡æ€å·²è¢«æˆåŠŸå¿½ç•¥ã€‚")
        print("   è§£é‡Šï¼šæ”¹å˜HSIè¾“å…¥å¯¹æ¨¡å‹æœ€ç»ˆé¢„æµ‹ç»“æœå‡ ä¹æ²¡æœ‰å½±å“ï¼Œè¿™å®Œå…¨ç¬¦åˆé¢„æœŸã€‚")
    else:
        print("âŒ éªŒè¯å¤±è´¥ï¼šHSIæ¨¡æ€ä»ç„¶åœ¨å½±å“æ¨¡å‹ã€‚")
        print("   è§£é‡Šï¼šæ”¹å˜HSIè¾“å…¥å¯¹æ¨¡å‹æœ€ç»ˆé¢„æµ‹ç»“æœäº§ç”Ÿäº†æ˜æ˜¾å½±å“ï¼Œè¯·æ£€æŸ¥ä»£ç ä¿®æ”¹ã€‚")
    print("="*60)


def parse_args():
    # å¤ç”¨å¹¶æ‰©å±• train_qwen_fixed.py çš„å‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser(description='è®­ç»ƒå¹¶éªŒè¯Qwenæ¨¡å‹')
    
    # è®­ç»ƒå‚æ•°
    parser.add_argument('--data_root', type=str, required=True)
    parser.add_argument('--batch_size', type=int, default=2)
    parser.add_argument('--num_workers', type=int, default=2)
    parser.add_argument('--epochs', type=int, default=2, help='è®­ç»ƒè½®æ•° (å»ºè®®è®¾ç½®ä¸º1æˆ–2ç”¨äºå¿«é€ŸéªŒè¯)')
    parser.add_argument('--lr', type=float, default=2e-5)
    parser.add_argument('--use_amp', action='store_true', help='ä½¿ç”¨æ··åˆç²¾åº¦ï¼ˆæ¨èå¯ç”¨ï¼‰')
    parser.add_argument('--accumulation_steps', type=int, default=4)
    parser.add_argument('--clip_grad', type=float, default=1.0)
    parser.add_argument('--early_stopping', type=int, default=10)
    parser.add_argument('--qwen_path', type=str, required=True)
    parser.add_argument('--output_dir', type=str, default='./outputs/train_and_verify')
    
    # éªŒè¯ä¸“ç”¨å‚æ•°
    parser.add_argument('--verify_rgb_image', type=str, required=True, help='ç”¨äºéªŒè¯çš„ä¸€å¼ RGBå›¾åƒè·¯å¾„')
    parser.add_argument('--num_classes', type=int, default=38, help='æ•°æ®é›†çš„ç±»åˆ«æ€»æ•° (ä¾‹å¦‚PlantVillageä¸º38)')

    # HSIå¼€å…³
    parser.add_argument('--use_hsi', action=argparse.BooleanOptionalAction, default=True)

    return parser.parse_args()

def main():
    args = parse_args()

    # å¼ºåˆ¶å¯ç”¨æ··åˆç²¾åº¦ä»¥ä¿è¯èƒ½è¿è¡Œ
    if not args.use_amp:
        print("è­¦å‘Š: è‡ªåŠ¨å¯ç”¨æ··åˆç²¾åº¦ä»¥èŠ‚çœæ˜¾å­˜ã€‚")
        args.use_amp = True

    # æ£€æŸ¥æ˜¯å¦å¤„äºâ€œæ— HSIâ€æ¨¡å¼
    if args.use_hsi:
        print("="*60)
        print("âš ï¸ è­¦å‘Š: æ­¤è„šæœ¬çš„éªŒè¯éƒ¨åˆ†ä»…åœ¨'æ— HSI'æ¨¡å¼ä¸‹æœ‰æ„ä¹‰ã€‚")
        print("è¯·ä½¿ç”¨ '--no-use_hsi' å‚æ•°æ¥è¿è¡Œæ­¤è„šæœ¬ä»¥è¿›è¡Œæœ‰æ•ˆéªŒè¯ã€‚")
        print("="*60)

    # --- è®­ç»ƒé˜¶æ®µ ---
    print("\n" + "#"*60)
    print("### å¼€å§‹è®­ç»ƒé˜¶æ®µ ###")
    print("#"*60)
    
    trainer = MemoryEfficientQwenTrainer(args)
    trainer.train()

    # --- éªŒè¯é˜¶æ®µ ---
    print("\n" + "#"*60)
    print("### è®­ç»ƒç»“æŸ, å¼€å§‹è‡ªåŠ¨éªŒè¯é˜¶æ®µ ###")
    print("#"*60)

    checkpoint_path = os.path.join(trainer.checkpoint_dir, 'best_model.pth')
    if not os.path.exists(checkpoint_path):
        print(f"é”™è¯¯: æ‰¾ä¸åˆ°è®­ç»ƒå¥½çš„æ¨¡å‹ {checkpoint_path}ã€‚éªŒè¯æ— æ³•è¿›è¡Œã€‚")
        return

    ### å…³é”®ä¿®å¤ï¼šåœ¨è¿™é‡Œé‡Šæ”¾è®­ç»ƒå™¨å’Œå®ƒå ç”¨çš„GPUæ˜¾å­˜ ###
    print("\né‡Šæ”¾è®­ç»ƒé˜¶æ®µå ç”¨çš„GPUæ˜¾å­˜...")
    del trainer  # åˆ é™¤trainerå¯¹è±¡ï¼Œé‡Šæ”¾å¯¹ç¬¬ä¸€ä¸ªæ¨¡å‹çš„å¼•ç”¨
    gc.collect() # è§¦å‘Pythonçš„åƒåœ¾å›æ”¶
    torch.cuda.empty_cache() # æŒ‡ç¤ºPyTorchæ¸…ç©ºæ˜¾å­˜ç¼“å­˜
    print("æ˜¾å­˜å·²æˆåŠŸé‡Šæ”¾ã€‚")
    ### ä¿®å¤ç»“æŸ ###
    
    run_verification_test(
        checkpoint_path=checkpoint_path,
        qwen_path=args.qwen_path,
        verify_rgb_image=args.verify_rgb_image,
        num_classes=args.num_classes,
        device='cuda' if torch.cuda.is_available() else 'cpu'
    )

if __name__ == '__main__':
    main()