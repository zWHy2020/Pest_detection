# scripts/train_fixed.py
"""
ä¿®å¤ç‰ˆè®­ç»ƒè„šæœ¬ - è§£å†³åŸæœ‰é—®é¢˜
é€‚ç”¨äºä¸ä½¿ç”¨Qwençš„åŸºçº¿æ¨¡å‹è®­ç»ƒ
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.cuda.amp import autocast, GradScaler
from torch.utils.tensorboard import SummaryWriter
import argparse
import os
import sys
from tqdm import tqdm
import json
import numpy as np
import warnings
warnings.filterwarnings('ignore')

PROJECT_ROOT = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, PROJECT_ROOT)

from models.main_model import MultiModalPestDetection
from data import create_dataloaders
from utils import calculate_metrics, AverageMeter, plot_training_curves


class FixedTrainer:
    """ä¿®å¤ç‰ˆè®­ç»ƒå™¨ - è§£å†³åŸæœ‰ä»£ç é—®é¢˜"""
    
    def __init__(self, args):
        self.args = args
        self.setup_device()
        self.setup_dataloader()
        self.setup_model()
        self.setup_optimizer()
        self.setup_training()
    
    def setup_device(self):
        """è®¾ç½®è®¾å¤‡"""
        if not torch.cuda.is_available():
            raise RuntimeError("éœ€è¦GPUè¿›è¡Œè®­ç»ƒ")
        
        self.device = torch.device('cuda:0')
        self.num_gpus = torch.cuda.device_count()
        
        print("\n" + "="*60)
        print("è®­ç»ƒå™¨åˆå§‹åŒ–")
        print("="*60)
        print(f"è®¾å¤‡: {self.device}")
        print(f"GPUæ•°é‡: {self.num_gpus}")
        
        # æ¸…ç†æ˜¾å­˜
        torch.cuda.empty_cache()
    
    def setup_dataloader(self):
        """åˆ›å»ºæ•°æ®åŠ è½½å™¨"""
        print("\nåˆ›å»ºæ•°æ®åŠ è½½å™¨...")
        
        self.train_loader, self.val_loader, _ = create_dataloaders(
            data_root=self.args.data_root,
            batch_size=self.args.batch_size,
            num_workers=self.args.num_workers,
            text_model_name='bert-base-chinese',
            use_augmentation=True
        )
        
        self.num_classes = self.train_loader.dataset.num_classes
        
        print(f"âœ“ è®­ç»ƒé›†: {len(self.train_loader.dataset)} æ ·æœ¬")
        print(f"âœ“ éªŒè¯é›†: {len(self.val_loader.dataset)} æ ·æœ¬")
        print(f"âœ“ ç±»åˆ«æ•°: {self.num_classes}")
    
    def setup_model(self):
        """åˆ›å»ºæ¨¡å‹ - ä¿®å¤ç‰ˆ"""
        print("\nåˆ›å»ºæ¨¡å‹...")
        
        try:
            self.model = MultiModalPestDetection(
                num_classes=self.num_classes,
                rgb_image_size=224,
                hsi_image_size=64,
                hsi_channels=224,
                text_model_name='bert-base-chinese',
                embed_dim=768,
                num_heads=12,
                dropout=0.1,
                fusion_layers=4,
                fusion_strategy='hierarchical',
                llm_model_name=None,  # ä¸ä½¿ç”¨LLM
                use_lora=False,
                freeze_encoders=False
            )
        except Exception as e:
            print(f"âŒ æ¨¡å‹åˆ›å»ºå¤±è´¥: {e}")
            print("\nå°è¯•ä½¿ç”¨ç®€åŒ–é…ç½®...")
            
            # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨æ›´ä¿å®ˆçš„é…ç½®
            self.model = MultiModalPestDetection(
                num_classes=self.num_classes,
                rgb_image_size=224,
                hsi_image_size=64,
                hsi_channels=224,
                text_model_name='bert-base-chinese',
                embed_dim=768,
                num_heads=8,  # å‡å°‘æ³¨æ„åŠ›å¤´æ•°
                dropout=0.1,
                fusion_layers=2,  # å‡å°‘èåˆå±‚
                fusion_strategy='concat',  # ä½¿ç”¨ç®€å•èåˆ
                llm_model_name=None,
                use_lora=False
            )
        
        # ç§»åˆ°è®¾å¤‡
        self.model = self.model.to(self.device)
        
        # ğŸ”§ ä¿®å¤ï¼šä¿å­˜åŸå§‹æ¨¡å‹å¼•ç”¨ï¼ˆè§£å†³DDPé—®é¢˜ï¼‰
        self.model_raw = self.model
        
        # å¤šGPU
        if self.num_gpus > 1:
            print(f"âœ“ ä½¿ç”¨DataParallel ({self.num_gpus} GPUs)")
            self.model = nn.DataParallel(self.model)
        
        # ç»Ÿè®¡å‚æ•°
        total_params = sum(p.numel() for p in self.model_raw.parameters())
        trainable_params = sum(p.numel() for p in self.model_raw.parameters() if p.requires_grad)
        
        print(f"âœ“ æ€»å‚æ•°: {total_params/1e6:.2f}M")
        print(f"âœ“ å¯è®­ç»ƒ: {trainable_params/1e6:.2f}M")
    
    def setup_optimizer(self):
        """è®¾ç½®ä¼˜åŒ–å™¨"""
        print("\nè®¾ç½®ä¼˜åŒ–å™¨...")
        
        self.optimizer = optim.AdamW(
            self.model.parameters(),
            lr=self.args.lr,
            weight_decay=0.01,
            betas=(0.9, 0.999)
        )
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨ - ä½¿ç”¨ä½™å¼¦é€€ç«
        self.scheduler = optim.lr_scheduler.CosineAnnealingLR(
            self.optimizer,
            T_max=self.args.epochs,
            eta_min=self.args.lr * 0.01
        )
        
        print("âœ“ ä¼˜åŒ–å™¨è®¾ç½®å®Œæˆ")
    
    def setup_training(self):
        """è®¾ç½®è®­ç»ƒç»„ä»¶"""
        # æ··åˆç²¾åº¦
        self.scaler = GradScaler() if self.args.use_amp else None
        
        # TensorBoard
        log_dir = os.path.join(self.args.output_dir, 'logs')
        os.makedirs(log_dir, exist_ok=True)
        self.writer = SummaryWriter(log_dir)
        
        # æ£€æŸ¥ç‚¹ç›®å½•
        self.checkpoint_dir = os.path.join(self.args.output_dir, 'checkpoints')
        os.makedirs(self.checkpoint_dir, exist_ok=True)
        
        # æœ€ä½³æŒ‡æ ‡
        self.best_val_acc = 0.0
        self.best_epoch = 0
        self.global_step = 0
        self.patience_counter = 0
        
        # å†å²
        self.history = {
            'train_loss': [],
            'val_loss': [],
            'val_acc': [],
            'val_f1': []
        }
    
    def train_epoch(self, epoch):
        """è®­ç»ƒä¸€ä¸ªepoch - ä¿®å¤ç‰ˆ"""
        self.model.train()
        
        losses = AverageMeter()
        cls_losses = AverageMeter()
        
        pbar = tqdm(self.train_loader, desc=f'Epoch {epoch}', ncols=100)
        
        for batch_idx, batch in enumerate(pbar):
            try:
                # ğŸ”§ ä¿®å¤ï¼šæ›´å®‰å…¨çš„æ•°æ®ç§»åŠ¨
                rgb = batch['rgb_images'].to(self.device, non_blocking=True)
                hsi = batch['hsi_images'].to(self.device, non_blocking=True)
                text_ids = batch['text_input_ids'].to(self.device, non_blocking=True)
                text_mask = batch['text_attention_mask'].to(self.device, non_blocking=True)
                labels = batch['labels'].to(self.device, non_blocking=True)
                
                # å‰å‘ä¼ æ’­
                if self.args.use_amp:
                    with autocast():
                        outputs = self.model(rgb, hsi, text_ids, text_mask, labels=labels)
                        loss = outputs['total_loss']
                        
                        # ğŸ”§ ä¿®å¤ï¼šå¤„ç†DataParallelè¿”å›çš„tuple
                        if isinstance(loss, tuple):
                            loss = loss[0]
                        loss = loss.mean()
                    
                    self.optimizer.zero_grad()
                    self.scaler.scale(loss).backward()
                    
                    if self.args.clip_grad > 0:
                        self.scaler.unscale_(self.optimizer)
                        torch.nn.utils.clip_grad_norm_(
                            self.model.parameters(), self.args.clip_grad
                        )
                    
                    self.scaler.step(self.optimizer)
                    self.scaler.update()
                else:
                    outputs = self.model(rgb, hsi, text_ids, text_mask, labels=labels)
                    loss = outputs['total_loss']
                    
                    if isinstance(loss, tuple):
                        loss = loss[0]
                    loss = loss.mean()
                    
                    self.optimizer.zero_grad()
                    loss.backward()
                    
                    if self.args.clip_grad > 0:
                        torch.nn.utils.clip_grad_norm_(
                            self.model.parameters(), self.args.clip_grad
                        )
                    
                    self.optimizer.step()
                
                # ç»Ÿè®¡
                losses.update(loss.item(), rgb.size(0))
                
                cls_loss = outputs.get('cls_loss', loss)
                if isinstance(cls_loss, tuple):
                    cls_loss = cls_loss[0]
                cls_losses.update(cls_loss.mean().item(), rgb.size(0))
                
                # æ›´æ–°è¿›åº¦æ¡
                pbar.set_postfix({
                    'loss': f'{losses.avg:.3f}',
                    'cls': f'{cls_losses.avg:.3f}'
                })
                
                # TensorBoard
                if batch_idx % 50 == 0:
                    self.writer.add_scalar('Train/Loss', losses.avg, self.global_step)
                    self.writer.add_scalar('Train/ClsLoss', cls_losses.avg, self.global_step)
                
                self.global_step += 1
                
            except RuntimeError as e:
                if 'out of memory' in str(e):
                    print(f'\nâŒ GPUæ˜¾å­˜ä¸è¶³! å°è¯•å‡å°batch_size')
                    print(f'å½“å‰batch_size: {self.args.batch_size}')
                    torch.cuda.empty_cache()
                    raise e
                else:
                    print(f'\nâŒ è®­ç»ƒé”™è¯¯: {e}')
                    raise e
        
        return losses.avg
    
    @torch.no_grad()
    def validate(self, epoch):
        """éªŒè¯ - ä¿®å¤ç‰ˆ"""
        self.model.eval()
        
        losses = AverageMeter()
        all_preds = []
        all_labels = []
        
        pbar = tqdm(self.val_loader, desc=f'Val {epoch}', ncols=100)
        
        for batch in pbar:
            try:
                rgb = batch['rgb_images'].to(self.device, non_blocking=True)
                hsi = batch['hsi_images'].to(self.device, non_blocking=True)
                text_ids = batch['text_input_ids'].to(self.device, non_blocking=True)
                text_mask = batch['text_attention_mask'].to(self.device, non_blocking=True)
                labels = batch['labels'].to(self.device, non_blocking=True)
                
                outputs = self.model(rgb, hsi, text_ids, text_mask, labels=labels)
                
                loss = outputs['total_loss']
                if isinstance(loss, tuple):
                    loss = loss[0]
                loss = loss.mean()
                
                logits = outputs['logits']
                preds = torch.argmax(logits, dim=1)
                
                losses.update(loss.item(), rgb.size(0))
                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())
                
                pbar.set_postfix({'loss': f'{losses.avg:.3f}'})
                
            except Exception as e:
                print(f'\nâŒ éªŒè¯é”™è¯¯: {e}')
                continue
        
        # è®¡ç®—æŒ‡æ ‡
        metrics = calculate_metrics(
            np.array(all_labels),
            np.array(all_preds),
            num_classes=self.num_classes
        )
        
        return losses.avg, metrics['accuracy'], metrics['f1']
    
    def save_checkpoint(self, epoch, val_acc, is_best=False):
        """ä¿å­˜æ£€æŸ¥ç‚¹"""
        # ğŸ”§ ä¿®å¤ï¼šä½¿ç”¨åŸå§‹æ¨¡å‹
        model_to_save = self.model_raw
        
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': model_to_save.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'scheduler_state_dict': self.scheduler.state_dict(),
            'val_acc': val_acc,
            'best_val_acc': self.best_val_acc,
            'args': vars(self.args)
        }
        
        # ä¿å­˜æœ€æ–°
        latest_path = os.path.join(self.checkpoint_dir, 'latest.pth')
        torch.save(checkpoint, latest_path)
        
        # ä¿å­˜æœ€ä½³
        if is_best:
            best_path = os.path.join(self.checkpoint_dir, 'best_model.pth')
            torch.save(checkpoint, best_path)
            print(f"   âœ“ ä¿å­˜æœ€ä½³æ¨¡å‹ (Acc: {val_acc:.4f})")
    
    def train(self):
        """å®Œæ•´è®­ç»ƒæµç¨‹"""
        print("\n" + "="*60)
        print("å¼€å§‹è®­ç»ƒ")
        print("="*60)
        
        for epoch in range(1, self.args.epochs + 1):
            print(f"\nEpoch {epoch}/{self.args.epochs}")
            print("-" * 60)
            
            try:
                # è®­ç»ƒ
                train_loss = self.train_epoch(epoch)
                
                # éªŒè¯
                val_loss, val_acc, val_f1 = self.validate(epoch)
                
                # å­¦ä¹ ç‡è°ƒåº¦
                self.scheduler.step()
                
                # è®°å½•
                self.history['train_loss'].append(train_loss)
                self.history['val_loss'].append(val_loss)
                self.history['val_acc'].append(val_acc)
                self.history['val_f1'].append(val_f1)
                
                # TensorBoard
                self.writer.add_scalar('Val/Loss', val_loss, epoch)
                self.writer.add_scalar('Val/Accuracy', val_acc, epoch)
                self.writer.add_scalar('Val/F1', val_f1, epoch)
                
                # æ‰“å°
                print(f"\nç»“æœ:")
                print(f"  Train Loss: {train_loss:.4f}")
                print(f"  Val Loss: {val_loss:.4f}")
                print(f"  Val Acc: {val_acc:.4f}")
                print(f"  Val F1: {val_f1:.4f}")
                
                # ä¿å­˜
                is_best = val_acc > self.best_val_acc
                if is_best:
                    self.best_val_acc = val_acc
                    self.best_epoch = epoch
                    self.patience_counter = 0
                else:
                    self.patience_counter += 1
                
                self.save_checkpoint(epoch, val_acc, is_best)
                
                # æ—©åœ
                if self.patience_counter >= self.args.early_stopping:
                    print(f"\næ—©åœè§¦å‘ (æœ€ä½³epoch: {self.best_epoch})")
                    break
                
            except Exception as e:
                print(f"\nâŒ Epoch {epoch} å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                
                # ä¿å­˜å½“å‰çŠ¶æ€
                self.save_checkpoint(epoch, 0.0, False)
                
                if 'out of memory' in str(e):
                    print("\nå»ºè®®:")
                    print("  1. å‡å° --batch_size")
                    print("  2. å‡å°‘ --num_workers")
                    print("  3. ä½¿ç”¨ --use_amp (æ··åˆç²¾åº¦)")
                    break
                else:
                    continue
        
        # ä¿å­˜å†å²
        history_path = os.path.join(self.args.output_dir, 'history.json')
        with open(history_path, 'w') as f:
            json.dump(self.history, f, indent=2)
        
        # ç»˜åˆ¶æ›²çº¿
        try:
            curves_path = os.path.join(self.args.output_dir, 'curves.png')
            plot_training_curves(self.history, save_path=curves_path)
        except Exception as e:
            print(f"è­¦å‘Š: ç»˜å›¾å¤±è´¥ - {e}")
        
        print("\n" + "="*60)
        print("âœ“ è®­ç»ƒå®Œæˆ!")
        print("="*60)
        print(f"æœ€ä½³å‡†ç¡®ç‡: {self.best_val_acc:.4f} (Epoch {self.best_epoch})")
        print(f"è¾“å‡ºç›®å½•: {self.args.output_dir}")
        print("="*60)
        
        self.writer.close()


def parse_args():
    parser = argparse.ArgumentParser(description='ä¿®å¤ç‰ˆè®­ç»ƒè„šæœ¬')
    
    # æ•°æ®
    parser.add_argument('--data_root', type=str, required=True,
                       help='æ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('--batch_size', type=int, default=16,
                       help='æ‰¹æ¬¡å¤§å°')
    parser.add_argument('--num_workers', type=int, default=4,
                       help='æ•°æ®åŠ è½½çº¿ç¨‹æ•°')
    
    # è®­ç»ƒ
    parser.add_argument('--epochs', type=int, default=100,
                       help='è®­ç»ƒè½®æ•°')
    parser.add_argument('--lr', type=float, default=1e-4,
                       help='å­¦ä¹ ç‡')
    parser.add_argument('--clip_grad', type=float, default=1.0,
                       help='æ¢¯åº¦è£å‰ª')
    parser.add_argument('--use_amp', action='store_true',
                       help='ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ')
    parser.add_argument('--early_stopping', type=int, default=20,
                       help='æ—©åœè½®æ•°')
    
    # è¾“å‡º
    parser.add_argument('--output_dir', type=str, default='./outputs/baseline_fixed',
                       help='è¾“å‡ºç›®å½•')
    
    return parser.parse_args()


def main():
    args = parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    
    # è®¾ç½®éšæœºç§å­
    torch.manual_seed(42)
    np.random.seed(42)
    torch.cuda.manual_seed_all(42)
    
    print("="*60)
    print("  ä¿®å¤ç‰ˆè®­ç»ƒè„šæœ¬")
    print("  è§£å†³åŸæœ‰ä»£ç çš„é—®é¢˜")
    print("="*60)
    
    try:
        # è®­ç»ƒ
        trainer = FixedTrainer(args)
        trainer.train()
        
    except Exception as e:
        print(f"\nâŒ è®­ç»ƒå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        
        print("\nè¯·æ£€æŸ¥:")
        print("  1. æ•°æ®é›†æ˜¯å¦å‡†å¤‡å¥½")
        print("  2. GPUæ˜¾å­˜æ˜¯å¦å……è¶³")
        print("  3. Qwenæ¨¡å‹æ˜¯å¦éœ€è¦åŠ è½½")


if __name__ == '__main__':
    main()